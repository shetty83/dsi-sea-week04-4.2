{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting \"Greenness\" Of Content\n",
    "\n",
    "This dataset comes from [stumbleupon](https://www.stumbleupon.com/), a web page recommender and was made available [here](https://www.kaggle.com/c/stumbleupon/download/train.tsv)\n",
    "\n",
    "A description of the columns is below\n",
    "\n",
    "FieldName|Type|Description\n",
    "---------|----|-----------\n",
    "url|string|Url of the webpage to be classified\n",
    "urlid|integer| StumbleUpon's unique identifier for each url\n",
    "boilerplate|json|Boilerplate text\n",
    "alchemy_category|string|Alchemy category (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "alchemy_category_score|double|Alchemy category score (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "avglinksize| double|Average number of words in each link\n",
    "commonLinkRatio_1|double|# of links sharing at least 1 word with 1 other links / # of links\n",
    "commonLinkRatio_2|double|# of links sharing at least 1 word with 2 other links / # of links\n",
    "commonLinkRatio_3|double|# of links sharing at least 1 word with 3 other links / # of links\n",
    "commonLinkRatio_4|double|# of links sharing at least 1 word with 4 other links / # of links\n",
    "compression_ratio|double|Compression achieved on this page via gzip (measure of redundancy)\n",
    "embed_ratio|double|Count of number of <embed> usage\n",
    "frameBased|integer (0 or 1)|A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "frameTagRatio|double|Ratio of iframe markups over total number of markups\n",
    "hasDomainLink|integer (0 or 1)|True (1) if it contains an <a> with an url with domain\n",
    "html_ratio|double|Ratio of tags vs text in the page\n",
    "image_ratio|double|Ratio of <img> tags vs text in the page\n",
    "is_news|integer (0 or 1) | True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "lengthyLinkDomain| integer (0 or 1)|True (1) if at least 3 <a> 's text contains more than 30 alphanumeric characters\n",
    "linkwordscore|double|Percentage of words on the page that are in hyperlink's text\n",
    "news_front_page| integer (0 or 1)|True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "non_markup_alphanum_characters|integer| Page's text's number of alphanumeric characters\n",
    "numberOfLinks|integer Number of <a>|markups\n",
    "numwords_in_url| double|Number of words in url\n",
    "parametrizedLinkRatio|double|A link is parametrized if it's url contains parameters or has an attached onClick event\n",
    "spelling_errors_ratio|double|Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "label|integer (0 or 1)|User-determined label. Either evergreen (1) or non-evergreen (0); available for train.tsv only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are 'evergreen' sites?\n",
    "- These are websites that always relevant like recipies or reviews (as opposed to current events)\n",
    "- Look at some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../assets/datasets/train.tsv', sep='\\t', na_values='?')\n",
    "\n",
    "# Extract the title and body from the boilerplate JSON text\n",
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', '')).fillna('')\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', '')).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM Sees Holographic Calls Air Breathing Batteries ibm sees holographic calls, air-breathing batteries</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Fully Electronic Futuristic Starting Gun That Eliminates Advantages in Races the fully electronic, futuristic starting gun that eliminates advantages in races the fully electronic, futuristic starting gun that eliminates advantages in races</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fruits that Fight the Flu fruits that fight the flu | cold &amp; flu | men's health</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Foolproof Tips for Better Sleep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 50 Coolest Jerseys You Didn t Know Existed coolest jerseys you haven't seen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                  title  \\\n",
       "0                                                                                                                                                IBM Sees Holographic Calls Air Breathing Batteries ibm sees holographic calls, air-breathing batteries   \n",
       "1  The Fully Electronic Futuristic Starting Gun That Eliminates Advantages in Races the fully electronic, futuristic starting gun that eliminates advantages in races the fully electronic, futuristic starting gun that eliminates advantages in races   \n",
       "2                                                                                                                                                                       Fruits that Fight the Flu fruits that fight the flu | cold & flu | men's health   \n",
       "3                                                                                                                                                                                                                   10 Foolproof Tips for Better Sleep    \n",
       "4                                                                                                                                                                       The 50 Coolest Jerseys You Didn t Know Existed coolest jerseys you haven't seen   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['title', 'label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In previous lessons, we added text features manually as below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['recipe'] = data['title'].str.lower().str.contains('recipe')\n",
    "data['electronic'] = data['title'].str.lower().str.contains('electronic')\n",
    "data['tips'] = data['title'].str.lower().str.contains('tips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can build a Logistic Regression model using scikit-learn and examine the coefficients\n",
    "- Examine the coefficients using the `examine_coefficients` function provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def examine_coefficients(model, df):\n",
    "    df = pd.DataFrame(\n",
    "        { 'Coefficient' : model.coef_[0] , 'Feature' : df.columns}\n",
    "    ).sort_values(by='Coefficient')\n",
    "    return df[df.Coefficient !=0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.441721</td>\n",
       "      <td>electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.620250</td>\n",
       "      <td>tips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.482849</td>\n",
       "      <td>recipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Coefficient     Feature\n",
       "1    -0.441721  electronic\n",
       "2     0.620250        tips\n",
       "0     2.482849      recipe"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "X = data[[\n",
    "        'recipe',\n",
    "        'electronic',\n",
    "        'tips'\n",
    "    ]]\n",
    "y = data.label\n",
    "\n",
    "\n",
    "model = LogisticRegression() \n",
    "\n",
    "model.fit(X, y) # This fits the model to learn the coefficients\n",
    "examine_coefficients(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can build text features in bulk as well using built-in preprocessing tools\n",
    "- `CountVectorizer` builds a feature per word automatically as we did manually for `recipe`, `electronic` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>2011</th>\n",
       "      <th>allrecipes</th>\n",
       "      <th>apple</th>\n",
       "      <th>baked</th>\n",
       "      <th>best</th>\n",
       "      <th>blog</th>\n",
       "      <th>butter</th>\n",
       "      <th>cake</th>\n",
       "      <th>cheese</th>\n",
       "      <th>chicken</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>com</th>\n",
       "      <th>cookies</th>\n",
       "      <th>cooking</th>\n",
       "      <th>cream</th>\n",
       "      <th>cupcakes</th>\n",
       "      <th>day</th>\n",
       "      <th>easy</th>\n",
       "      <th>fashion</th>\n",
       "      <th>food</th>\n",
       "      <th>foods</th>\n",
       "      <th>free</th>\n",
       "      <th>health</th>\n",
       "      <th>healthy</th>\n",
       "      <th>home</th>\n",
       "      <th>homemade</th>\n",
       "      <th>illustrated</th>\n",
       "      <th>insidershealth</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>life</th>\n",
       "      <th>make</th>\n",
       "      <th>new</th>\n",
       "      <th>news</th>\n",
       "      <th>peanut</th>\n",
       "      <th>photos</th>\n",
       "      <th>pie</th>\n",
       "      <th>recipe</th>\n",
       "      <th>recipes</th>\n",
       "      <th>si</th>\n",
       "      <th>sports</th>\n",
       "      <th>style</th>\n",
       "      <th>sweet</th>\n",
       "      <th>swimsuit</th>\n",
       "      <th>technology</th>\n",
       "      <th>time</th>\n",
       "      <th>tips</th>\n",
       "      <th>video</th>\n",
       "      <th>ways</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  2011  allrecipes  apple  baked  best  blog  butter  cake  cheese  \\\n",
       "0   0     0           0      0      0     0     0       0     0       0   \n",
       "1   0     0           0      0      0     0     0       0     0       0   \n",
       "2   0     0           0      0      0     0     0       0     0       0   \n",
       "3   1     0           0      0      0     0     0       0     0       0   \n",
       "4   0     0           0      0      0     0     0       0     0       0   \n",
       "\n",
       "   chicken  chocolate  com  cookies  cooking  cream  cupcakes  day  easy  \\\n",
       "0        0          0    0        0        0      0         0    0     0   \n",
       "1        0          0    0        0        0      0         0    0     0   \n",
       "2        0          0    0        0        0      0         0    0     0   \n",
       "3        0          0    0        0        0      0         0    0     0   \n",
       "4        0          0    0        0        0      0         0    0     0   \n",
       "\n",
       "   fashion  food  foods  free  health  healthy  home  homemade  illustrated  \\\n",
       "0        0     0      0     0       0        0     0         0            0   \n",
       "1        0     0      0     0       0        0     0         0            0   \n",
       "2        0     0      0     0       1        0     0         0            0   \n",
       "3        0     0      0     0       0        0     0         0            0   \n",
       "4        0     0      0     0       0        0     0         0            0   \n",
       "\n",
       "   insidershealth  kitchen  life  make  new  news  peanut  photos  pie  \\\n",
       "0               0        0     0     0    0     0       0       0    0   \n",
       "1               0        0     0     0    0     0       0       0    0   \n",
       "2               0        0     0     0    0     0       0       0    0   \n",
       "3               0        0     0     0    0     0       0       0    0   \n",
       "4               0        0     0     0    0     0       0       0    0   \n",
       "\n",
       "   recipe  recipes  si  sports  style  sweet  swimsuit  technology  time  \\\n",
       "0       0        0   0       0      0      0         0           0     0   \n",
       "1       0        0   0       0      0      0         0           0     0   \n",
       "2       0        0   0       0      0      0         0           0     0   \n",
       "3       0        0   0       0      0      0         0           0     0   \n",
       "4       0        0   0       0      0      0         0           0     0   \n",
       "\n",
       "   tips  video  ways  world  \n",
       "0     0      0     0      0  \n",
       "1     0      0     0      0  \n",
       "2     0      0     0      0  \n",
       "3     1      0     0      0  \n",
       "4     0      0     0      0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer(\n",
    "    binary=True,  # Create binary features\n",
    "    stop_words='english', # Ignore common words such as 'the', 'and'\n",
    "    max_features=50, # Only use the top 50 most common words\n",
    ")\n",
    "\n",
    "\n",
    "# This builds a matrix with a row per website (or data point) and column per word (using all words in the dataset)\n",
    "X = v.fit_transform(data.title).todense()\n",
    "X = pd.DataFrame(X, columns=v.get_feature_names())\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the input matrix above, fit a logistic regression model using L1 regularization\n",
    "- Change the `C` parameter\n",
    "    - how do the coefficients change? (use `examine_coeffcients`)\n",
    "    - how does the model perfomance change (using AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.707912034622, all: [ 0.69910787  0.71602434  0.7086039 ]\n",
      "mean precision: 0.84160828756, all: [ 0.81566265  0.85534591  0.8538163 ]\n",
      "mean recall: 0.53134789061, all: [ 0.53475513  0.53754941  0.52173913]\n",
      "mean roc_auc: 0.766789309864, all: [ 0.76488217  0.77273814  0.76274761]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1, penalty='l1')\n",
    "\n",
    "logreg.fit(X, y)\n",
    "examine_coefficients(logreg, X)\n",
    "\n",
    "Y_pred = logreg.predict(X)\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(logreg, X, y, scoring=metric)\n",
    "    print(\"mean {}: {}, all: {}\".format(metric, scores.mean(), scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the input matrix above, fit a logistic regression model using L2 regularization\n",
    "- Change the `C` parameter - how do the coefficients change? (use `examine_coeffcients`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.532522032526, all: [ 0.53041363  0.53630832  0.53084416]\n",
      "mean precision: 0.52356330838, all: [ 0.52242525  0.5255658   0.52269888]\n",
      "mean recall: 0.992360031387, all: [ 0.99368088  0.99130435  0.99209486]\n",
      "mean roc_auc: 0.761040073745, all: [ 0.7549503   0.76576976  0.76240016]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.0000001, penalty='l2')\n",
    "\n",
    "logreg.fit(X, y)\n",
    "\n",
    "Y_pred = logreg.predict(X)\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(logreg, X, y, scoring=metric)\n",
    "    print(\"mean {}: {}, all: {}\".format(metric, scores.mean(), scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.705860842392, all: [ 0.69041769  0.71498771  0.71217712]\n",
      "mean precision: 0.842588033976, all: [ 0.84297521  0.84962406  0.83516484]\n",
      "mean recall: 0.525156907966, all: [ 0.48803828  0.54066986  0.54676259]\n",
      "mean roc_auc: 0.773235386849, all: [ 0.75092431  0.78640472  0.78237713]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, stratify=y, random_state=77)\n",
    "\n",
    "logreg_cv = LogisticRegressionCV(Cs=15, cv=5, penalty='l2', scoring='accuracy', solver='liblinear')\n",
    "\n",
    "logreg_cv.fit(X_train, Y_train)\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(logreg, X_test, Y_test, scoring=metric)\n",
    "    print(\"mean {}: {}, all: {}\".format(metric, scores.mean(), scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_vals = [0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]\n",
    "penalties = ['l1','l2']\n",
    "\n",
    "gs = GridSearchCV(logreg, {'penalty':penalties, 'C':C_vals}, verbose=True, cv=5, scoring='f1_macro')\n",
    "gs.fit(X, Y)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
